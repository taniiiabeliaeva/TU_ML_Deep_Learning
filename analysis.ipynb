{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "import math\n",
    "from torchtext.data.metrics import bleu_score\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "from main import get_model\n",
    "from dataset.dataset import (\n",
    "    LoaderConstructor,\n",
    "    create_poetryfoundation_dataset,\n",
    "    create_poems_txt_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    \"dataset\": \"poetryfoundation\", \n",
    "    \"batch_size\": 3,\n",
    "    \"max_length\": 50,\n",
    "    \"embed_dim\": 512,\n",
    "    \"min_text_length\": 50, \n",
    "}\n",
    "\n",
    "# Load the dataset\n",
    "if cfg[\"dataset\"] == \"poetryfoundation\":\n",
    "    dataset = create_poetryfoundation_dataset(os.getcwd())\n",
    "elif cfg[\"dataset\"] == \"poems_txt\":\n",
    "    dataset = create_poems_txt_dataset(os.getcwd())\n",
    "\n",
    "# Construct the dataloaders\n",
    "lc = LoaderConstructor(\n",
    "    dataset=dataset,\n",
    "    batch_size=cfg[\"batch_size\"],\n",
    "    max_length=cfg[\"max_length\"],\n",
    "    labels_sequence=False,\n",
    "    min_freq=3,\n",
    ")\n",
    "loaders = {}\n",
    "for loader in [\"train\", \"validation\", \"test\"]:\n",
    "    loaders[loader] = lc.construct_loader(split=loader)\n",
    "\n",
    "input_size = loaders[\"train\"].dataset.input_size\n",
    "vocab_size = lc.vocab_size\n",
    "output_size = lc.output_size\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_name):\n",
    "    \"\"\"Loads the model with trained weights\"\"\"\n",
    "    model = get_model(\n",
    "        model=model_name,\n",
    "        vocab_size=vocab_size,\n",
    "        embed_dim=cfg[\"embed_dim\"],\n",
    "        seq_len=input_size,\n",
    "        output_dim=output_size,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    model_weights = {\n",
    "        \"lstm\": f\"trained_models/lstm_{cfg['dataset']}_lr=0_001_lastepoch.pt\", # MAYBE WE NEED TO TRY WITH lstm_poetryfoundation_lr=0_001_best.pt AND THINK ABOUT LERNNG RATE\n",
    "        \"transformer\": f\"trained_models/transformer_{cfg['dataset']}_lr=0_001_lastepoch.pt\",\n",
    "    }\n",
    "\n",
    "    model.load_state_dict(torch.load(model_weights[model_name]))\n",
    "    model.to(device).eval()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "accuracy_metric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=output_size).to(device)\n",
    "top3_accuracy_metric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=output_size, top_k=5).to(device)\n",
    "\n",
    "def calculate_perplexity(loss):\n",
    "    return math.exp(loss)\n",
    "\n",
    "def calculate_bleu(candidate, references):\n",
    "    return bleu_score([candidate], [[ref] for ref in references])\n",
    "\n",
    "def calculate_rouge(candidate, reference):\n",
    "    scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n",
    "    scores = scorer.score(candidate, reference)\n",
    "    return scores\n",
    "\n",
    "def evaluate(model, batch, test=False, n_next_words=5):\n",
    "    \"\"\"Evaluates the model and predicts next words for poetry\"\"\"\n",
    "    inputs, labels = batch[\"input_ids\"].to(device), batch[\"labels\"].to(device)\n",
    "    labels = labels.contiguous().view(-1)\n",
    "    output = model(inputs).view(-1, output_size)\n",
    "\n",
    "    loss = criterion(output, labels).item()\n",
    "    accuracy = accuracy_metric(torch.argmax(output, dim=-1), labels).item()\n",
    "    perplexity = calculate_perplexity(loss)\n",
    "    top3_accuracy = top3_accuracy_metric(output, labels).item()\n",
    "\n",
    "    print(f\"Loss: {loss:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Perplexity: {perplexity:.4f}\")\n",
    "    print(f\"Top-3 Accuracy: {top3_accuracy:.4f}\")\n",
    "\n",
    "    total_bleu = 0\n",
    "    total_rouge = {\"rouge1\": 0, \"rouge2\": 0, \"rougeL\": 0}\n",
    "    num_samples = batch[\"input_ids\"].shape[0]\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        input_text = lc.tokenizer.decode(inputs[i].tolist(), target=False)\n",
    "        target_text = lc.tokenizer.decode(labels[i].unsqueeze(0).tolist(), target=True)[0]\n",
    "        predicted_text = lc.tokenizer.decode(torch.argmax(output[i], dim=-1).unsqueeze(0).tolist(), target=True)[0]\n",
    "\n",
    "        print(f\"Input: {' '.join(input_text)}\")\n",
    "        print(f\"Target: {target_text}\")\n",
    "        print(f\"Predicted: {predicted_text}\")\n",
    "        print()\n",
    "\n",
    "        bleu = calculate_bleu(predicted_text.split(), [target_text.split()])\n",
    "        total_bleu += bleu\n",
    "\n",
    "        rouge = calculate_rouge(predicted_text, target_text)\n",
    "        for key in total_rouge.keys():\n",
    "            total_rouge[key] += rouge[key].fmeasure\n",
    "\n",
    "    avg_bleu = total_bleu / num_samples\n",
    "    avg_rouge = {key: total_rouge[key] / num_samples for key in total_rouge}\n",
    "\n",
    "    print(f\"Avg BLEU Score: {avg_bleu}\")\n",
    "    print(f\"Avg ROUGE Score: {avg_rouge}\")\n",
    "\n",
    "    # Predict next words for new poetic lines\n",
    "    if test:\n",
    "        mini_dataset = [\n",
    "            {\"text\": \"The moonlight danced upon the silent lake\", \"predictions\": []},\n",
    "            {\"text\": \"A whisper of wind through the autumn leaves\", \"predictions\": []},\n",
    "            {\"text\": \"The poet's heart was filled with endless wonder\", \"predictions\": []},\n",
    "            {\"text\": \"Beneath the stars, she walked alone\", \"predictions\": []},\n",
    "            {\"text\": \"His voice was music, soft and deep\", \"predictions\": []},\n",
    "        ]\n",
    "\n",
    "        # Tokenize the texts\n",
    "        tokenised_samples = lc.tokenizer.create_tokens(mini_dataset)\n",
    "        tokenised_samples = lc.tokenizer.pad_sequences(tokenised_samples)\n",
    "        encodings = lc.tokenizer.encode(tokenised_samples)\n",
    "\n",
    "        # No labels in this case\n",
    "        inputs = encodings[:, 1:].to(device)\n",
    "        decoded_inputs = [lc.tokenizer.decode(sample.tolist(), target=False) for sample in inputs]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for _ in range(n_next_words):\n",
    "                output = model(inputs)\n",
    "                next_token = torch.argmax(output, dim=-1)\n",
    "\n",
    "                # Decode the tokens to get the words\n",
    "                decoded_tokens = lc.tokenizer.decode(next_token.tolist(), target=True)\n",
    "\n",
    "                # Encode the tokens to get the input for the next iteration\n",
    "                encoded_tokens = lc.tokenizer.encode([decoded_tokens]).to(device)\n",
    "\n",
    "                # Concatenate the input with the new tokens\n",
    "                inputs = torch.cat([inputs[:, 1:], encoded_tokens.reshape(-1, 1)], dim=1)\n",
    "\n",
    "                for i, token in enumerate(decoded_tokens):\n",
    "                    mini_dataset[i][\"predictions\"].append(token)\n",
    "\n",
    "        for sample, input_sentence in zip(mini_dataset, decoded_inputs):\n",
    "            print(f\"Input: {' '.join(input_sentence)}\")\n",
    "            print(f\"Predicted next words: {' '.join(sample['predictions'])}\")\n",
    "            print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Evaluating model: lstm\n",
      "**************************************************\n",
      "Loss: 4.2639\n",
      "Accuracy: 0.3333\n",
      "Perplexity: 71.0861\n",
      "Top-3 Accuracy: 0.3333\n",
      "Input: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Target: radio\n",
      "Predicted: psalm\n",
      "\n",
      "Input: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> leaving the\n",
      "Target: hospital\n",
      "Predicted: hospital\n",
      "\n",
      "Input: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Target: october\n",
      "Predicted: psalm\n",
      "\n",
      "Avg BLEU Score: 0.0000\n",
      "Avg ROUGE Score: {'rouge1': 0.3333333333333333, 'rouge2': 0.0, 'rougeL': 0.3333333333333333}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Evaluating model: transformer\n",
      "**************************************************\n",
      "Loss: 4.1905\n",
      "Accuracy: 0.3333\n",
      "Perplexity: 66.0584\n",
      "Top-3 Accuracy: 0.3333\n",
      "Input: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Target: radio\n",
      "Predicted: song\n",
      "\n",
      "Input: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> leaving the\n",
      "Target: hospital\n",
      "Predicted: hospital\n",
      "\n",
      "Input: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Target: october\n",
      "Predicted: song\n",
      "\n",
      "Avg BLEU Score: 0.0000\n",
      "Avg ROUGE Score: {'rouge1': 0.3333333333333333, 'rouge2': 0.0, 'rougeL': 0.3333333333333333}\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "# **Run Evaluation**\n",
    "batch = next(iter(loaders[\"train\"]))\n",
    "for model_name in [\"lstm\", \"transformer\"]:\n",
    "    print(\"*\" * 50)\n",
    "    print(f\"Evaluating model: {model_name}\")\n",
    "    print(\"*\" * 50)\n",
    "    model = initialize_model(model_name)\n",
    "    evaluate(model, batch)\n",
    "    print(\"*\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Evaluating model: lstm\n",
      "**************************************************\n",
      "Loss: 6.5365\n",
      "Accuracy: 0.0000\n",
      "Perplexity: 689.8750\n",
      "Top-3 Accuracy: 0.0000\n",
      "Input: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> too\n",
      "Target: much\n",
      "Predicted: moth\n",
      "\n",
      "Input: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <oov> deaf\n",
      "Target: heaven\n",
      "Predicted: book\n",
      "\n",
      "Input: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> long too long\n",
      "Target: america\n",
      "Predicted: sound\n",
      "\n",
      "Avg BLEU Score: 0.0000\n",
      "Avg ROUGE Score: {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0}\n",
      "Input: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> the moonlight <oov> upon the silent lake\n",
      "Predicted next words: tragedy center story alone forget\n",
      "\n",
      "Input: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> a <oov> of wind through the autumn leaves\n",
      "Predicted next words: now now now now d\n",
      "\n",
      "Input: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> the poet heart was <oov> with <oov> wonder\n",
      "Predicted next words: forget sonnets this face rhymes\n",
      "\n",
      "Input: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> beneath the stars she <oov> alone\n",
      "Predicted next words: tonight now think now old\n",
      "\n",
      "Input: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> his voice was music soft and deep\n",
      "Predicted next words: out out out out out\n",
      "\n",
      "**************************************************\n",
      "**************************************************\n",
      "Evaluating model: transformer\n",
      "**************************************************\n",
      "Loss: 7.6318\n",
      "Accuracy: 0.0000\n",
      "Perplexity: 2062.7079\n",
      "Top-3 Accuracy: 0.0000\n",
      "Input: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> too\n",
      "Target: much\n",
      "Predicted: die\n",
      "\n",
      "Input: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <oov> deaf\n",
      "Target: heaven\n",
      "Predicted: republic\n",
      "\n",
      "Input: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> long too long\n",
      "Target: america\n",
      "Predicted: die\n",
      "\n",
      "Avg BLEU Score: 0.0000\n",
      "Avg ROUGE Score: {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0}\n",
      "Input: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> the moonlight <oov> upon the silent lake\n",
      "Predicted next words: october october october time year\n",
      "\n",
      "Input: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> a <oov> of wind through the autumn leaves\n",
      "Predicted next words: race year year day day\n",
      "\n",
      "Input: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> the poet heart was <oov> with <oov> wonder\n",
      "Predicted next words: man sky sky sky sky\n",
      "\n",
      "Input: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> beneath the stars she <oov> alone\n",
      "Predicted next words: world world world it all\n",
      "\n",
      "Input: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> his voice was music soft and deep\n",
      "Predicted next words: lone tomorrow tomorrow tomorrow tomorrow\n",
      "\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(loaders[\"test\"]))\n",
    "for model_name in [\"lstm\", \"transformer\"]:\n",
    "    print(\"*\" * 50)\n",
    "    print(f\"Evaluating model: {model_name}\")\n",
    "    print(\"*\" * 50)\n",
    "    model = initialize_model(model_name)\n",
    "    evaluate(model, batch, test=True, n_next_words=5)\n",
    "    print(\"*\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlconda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
