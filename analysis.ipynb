{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "import math\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from main import get_model\n",
    "from dataset.dataset import (\n",
    "    LoaderConstructor,\n",
    "    create_poetryfoundation_dataset,\n",
    "    create_story_txt_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = [\n",
    "   {\n",
    "        \"dataset\": \"poetryfoundation\",\n",
    "        \"batch_size\": 3,\n",
    "        \"max_length\": 50,\n",
    "        \"embed_dim\": 512,\n",
    "        \"min_text_length\": 50,\n",
    "    },\n",
    "    {\n",
    "        \"dataset\": \"story_txt\",\n",
    "        \"batch_size\": 3,\n",
    "        \"max_length\": 50,\n",
    "        \"embed_dim\": 512,\n",
    "        \"min_text_length\": 50,\n",
    "    }\n",
    "]\n",
    "\n",
    "def load_and_construct(cfg):\n",
    "    print(f\"\\nEvaluating dataset: {cfg['dataset']}\")\n",
    "    \n",
    "    # Load the dataset\n",
    "    if cfg[\"dataset\"] == \"poetryfoundation\":\n",
    "        dataset = create_poetryfoundation_dataset(os.getcwd())\n",
    "    elif cfg[\"dataset\"] == \"story_txt\":\n",
    "        dataset = create_story_txt_dataset(os.getcwd())\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown dataset: {cfg['dataset']}\")\n",
    "\n",
    "    # Construct the dataloaders\n",
    "    lc = LoaderConstructor(\n",
    "        dataset=dataset,\n",
    "        batch_size=cfg[\"batch_size\"],\n",
    "        max_length=cfg[\"max_length\"],\n",
    "        labels_sequence=False,\n",
    "        min_freq=3,\n",
    "    )\n",
    "\n",
    "    loaders = {loader: lc.construct_loader(split=loader) for loader in [\"train\", \"validation\", \"test\"]}\n",
    "\n",
    "    input_size = getattr(loaders[\"train\"].dataset, \"input_size\", None)\n",
    "    if input_size is None:\n",
    "        raise AttributeError(\"Dataset object does not have 'input_size' attribute. Check implementation.\")\n",
    "\n",
    "    vocab_size = lc.vocab_size\n",
    "    output_size = lc.output_size\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "    \n",
    "    return dataset, lc, loaders, input_size, vocab_size, output_size, device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model_weights(dataset):\n",
    "    \"\"\"Finds the best model weight files for both LSTM and Transformer based on the highest accuracy.\"\"\"\n",
    "    model_types = [\"lstm\", \"transformer\"]\n",
    "    best_models = {}\n",
    "    \n",
    "    for model_name in model_types:\n",
    "        model_files = [\n",
    "            f\"trained_models/{model_name}_{dataset}_lr=0_001_best.pt\",\n",
    "            f\"trained_models/{model_name}_{dataset}_lr=0_0001_best.pt\",\n",
    "            f\"trained_models/{model_name}_{dataset}_lr=0_0005_best.pt\"\n",
    "        ]\n",
    "        \n",
    "        best_model = None\n",
    "        best_accuracy = -1\n",
    "        \n",
    "        for model_file in model_files:\n",
    "            stats_file = model_file.replace(\"_best.pt\", \"_stats.json\")\n",
    "            if os.path.exists(stats_file):\n",
    "                with open(stats_file, \"r\") as f:\n",
    "                    stats = json.load(f)\n",
    "                    \n",
    "                    for lr, details in stats.items():\n",
    "                        if \"val_accuracy\" in details:\n",
    "                            accuracy = details[\"val_accuracy\"]\n",
    "                            if accuracy > best_accuracy:\n",
    "                                best_accuracy = accuracy\n",
    "                                best_model = details[\"best_model\"]\n",
    "        \n",
    "        if best_model:\n",
    "            best_models[model_name] = best_model\n",
    "\n",
    "    return best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights = {\n",
    "    \"poetryfoundation\": get_best_model_weights(\"poetryfoundation\"),\n",
    "    \"story_txt\": get_best_model_weights(\"story_txt\")\n",
    "}\n",
    "\n",
    "def initialize_model(model_name, vocab_size, input_size, output_size, device, cfg):\n",
    "    \"\"\"Loads the model with trained weights\"\"\"\n",
    "    model = get_model(\n",
    "        model=model_name,\n",
    "        vocab_size=vocab_size,\n",
    "        embed_dim=cfg[\"embed_dim\"],\n",
    "        seq_len=input_size,\n",
    "        output_dim=output_size,\n",
    "        device=device,\n",
    "    )\n",
    "    best_model_weight = model_weights[cfg['dataset']][model_name]\n",
    "    \n",
    "    model.load_state_dict(torch.load(best_model_weight))\n",
    "    model.to(device).eval()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity(loss):\n",
    "    return math.exp(loss)\n",
    "\n",
    "def evaluate(model, batch, output_size, device, lc, test=False, n_next_words=5):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    accuracy_metric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=output_size).to(device)\n",
    "    top3_accuracy_metric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=output_size, top_k=5).to(device)\n",
    "    \n",
    "    \"\"\"Evaluates the model and predicts next words for poetry\"\"\"\n",
    "    inputs, labels = batch[\"input_ids\"].to(device), batch[\"labels\"].to(device)\n",
    "    labels = labels.contiguous().view(-1)\n",
    "    output = model(inputs).view(-1, output_size)\n",
    "\n",
    "    loss = criterion(output, labels).item()\n",
    "    accuracy = accuracy_metric(torch.argmax(output, dim=-1), labels).item()\n",
    "    perplexity = calculate_perplexity(loss)\n",
    "    top3_accuracy = top3_accuracy_metric(output, labels).item()\n",
    "\n",
    "    print(f\"Loss: {loss:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Perplexity: {perplexity:.4f}\")\n",
    "    print(f\"Top-3 Accuracy: {top3_accuracy:.4f}\")\n",
    "\n",
    "    # Predict next words for new poetic lines\n",
    "    if test:\n",
    "        mini_dataset = [\n",
    "            {\"text\": \"The moonlight danced upon the silent lake\", \"predictions\": []},\n",
    "            {\"text\": \"A whisper of wind through the autumn leaves\", \"predictions\": []},\n",
    "            {\"text\": \"The poet's heart was filled with endless wonder\", \"predictions\": []},\n",
    "            {\"text\": \"Beneath the stars, she walked alone\", \"predictions\": []},\n",
    "            {\"text\": \"His voice was music, soft and deep\", \"predictions\": []},\n",
    "        ]\n",
    "\n",
    "        # Tokenize the texts\n",
    "        tokenised_samples = lc.tokenizer.create_tokens(mini_dataset)\n",
    "        tokenised_samples = lc.tokenizer.pad_sequences(tokenised_samples)\n",
    "        encodings = lc.tokenizer.encode(tokenised_samples)\n",
    "\n",
    "        # No labels in this case\n",
    "        inputs = encodings[:, 1:].to(device)\n",
    "        decoded_inputs = [lc.tokenizer.decode(sample.tolist(), target=False) for sample in inputs]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for _ in range(n_next_words):\n",
    "                output = model(inputs)\n",
    "                next_token = torch.argmax(output, dim=-1)\n",
    "\n",
    "                # Decode the tokens to get the words\n",
    "                decoded_tokens = lc.tokenizer.decode(next_token.tolist(), target=True)\n",
    "\n",
    "                # Encode the tokens to get the input for the next iteration\n",
    "                encoded_tokens = lc.tokenizer.encode([decoded_tokens]).to(device)\n",
    "\n",
    "                # Concatenate the input with the new tokens\n",
    "                inputs = torch.cat([inputs[:, 1:], encoded_tokens.reshape(-1, 1)], dim=1)\n",
    "\n",
    "                for i, token in enumerate(decoded_tokens):\n",
    "                    mini_dataset[i][\"predictions\"].append(token)\n",
    "\n",
    "        for sample, input_sentence in zip(mini_dataset, decoded_inputs):\n",
    "            print(f\"Input: {' '.join(input_sentence)}\")\n",
    "            print(f\"Predicted next words: {' '.join(sample['predictions'])}\")\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating dataset: poetryfoundation\n",
      "**************************************************\n",
      "Evaluating model: lstm\n",
      "**************************************************\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for LSTM:\n\tsize mismatch for embedding.weight: copying a param with shape torch.Size([2060, 512]) from checkpoint, the shape in current model is torch.Size([2138, 512]).\n\tsize mismatch for fc.weight: copying a param with shape torch.Size([2058, 512]) from checkpoint, the shape in current model is torch.Size([2136, 512]).\n\tsize mismatch for fc.bias: copying a param with shape torch.Size([2058]) from checkpoint, the shape in current model is torch.Size([2136]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43minitialize_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m evaluate(model, batch, output_size, device, lc)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m50\u001b[39m)\n",
      "Cell \u001b[0;32mIn[31], line 18\u001b[0m, in \u001b[0;36minitialize_model\u001b[0;34m(model_name, vocab_size, input_size, output_size, device, cfg)\u001b[0m\n\u001b[1;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m get_model(\n\u001b[1;32m      9\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel_name,\n\u001b[1;32m     10\u001b[0m     vocab_size\u001b[38;5;241m=\u001b[39mvocab_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     16\u001b[0m best_model_weight \u001b[38;5;241m=\u001b[39m model_weights[cfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m]][model_name]\n\u001b[0;32m---> 18\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_model_weight\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mlconda/lib/python3.10/site-packages/torch/nn/modules/module.py:2152\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2147\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2148\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2149\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2153\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for LSTM:\n\tsize mismatch for embedding.weight: copying a param with shape torch.Size([2060, 512]) from checkpoint, the shape in current model is torch.Size([2138, 512]).\n\tsize mismatch for fc.weight: copying a param with shape torch.Size([2058, 512]) from checkpoint, the shape in current model is torch.Size([2136, 512]).\n\tsize mismatch for fc.bias: copying a param with shape torch.Size([2058]) from checkpoint, the shape in current model is torch.Size([2136])."
     ]
    }
   ],
   "source": [
    "# **Run Evaluation**\n",
    "dataset, lc, loaders, input_size, vocab_size, output_size, device = load_and_construct(cfg[0])\n",
    "batch = next(iter(loaders[\"train\"]))\n",
    "for model_name in [\"lstm\", \"transformer\"]:\n",
    "    print(\"*\" * 50)\n",
    "    print(f\"Evaluating model: {model_name}\")\n",
    "    print(\"*\" * 50)\n",
    "    model = initialize_model(model_name, vocab_size, input_size, output_size, device, cfg[0])\n",
    "    evaluate(model, batch, output_size, device, lc)\n",
    "    print(\"*\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Evaluating model: lstm\n",
      "**************************************************\n",
      "Loss: 7.8521\n",
      "Accuracy: 0.0000\n",
      "Perplexity: 2571.0934\n",
      "Top-3 Accuracy: 0.0000\n",
      "Input: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> the moonlight <oov> upon the silent lake\n",
      "Predicted next words: song life life\n",
      "\n",
      "Input: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> a <oov> of wind through the autumn leaves\n",
      "Predicted next words: world year day\n",
      "\n",
      "Input: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> the poet heart was <oov> with <oov> wonder\n",
      "Predicted next words: me me think\n",
      "\n",
      "Input: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> beneath the stars she <oov> alone\n",
      "Predicted next words: me me you\n",
      "\n",
      "Input: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> his voice was music soft and deep\n",
      "Predicted next words: now life love\n",
      "\n",
      "**************************************************\n",
      "**************************************************\n",
      "Evaluating model: transformer\n",
      "**************************************************\n",
      "Loss: 7.6517\n",
      "Accuracy: 0.0000\n",
      "Perplexity: 2104.1465\n",
      "Top-3 Accuracy: 0.0000\n",
      "Input: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> the moonlight <oov> upon the silent lake\n",
      "Predicted next words: october me man\n",
      "\n",
      "Input: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> a <oov> of wind through the autumn leaves\n",
      "Predicted next words: me day room\n",
      "\n",
      "Input: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> the poet heart was <oov> with <oov> wonder\n",
      "Predicted next words: me day room\n",
      "\n",
      "Input: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> beneath the stars she <oov> alone\n",
      "Predicted next words: me still life\n",
      "\n",
      "Input: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> his voice was music soft and deep\n",
      "Predicted next words: again again again\n",
      "\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(loaders[\"test\"]))\n",
    "for model_name in [\"lstm\", \"transformer\"]:\n",
    "    print(\"*\" * 50)\n",
    "    print(f\"Evaluating model: {model_name}\")\n",
    "    print(\"*\" * 50)\n",
    "    model = initialize_model(model_name, vocab_size, input_size, output_size, device, cfg[0])\n",
    "    evaluate(model, batch, output_size, device, lc, test=True, n_next_words=3)\n",
    "    print(\"*\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating dataset: story_txt\n",
      "**************************************************\n",
      "Evaluating model: transformer\n",
      "**************************************************\n",
      "Loss: 0.1580\n",
      "Accuracy: 1.0000\n",
      "Perplexity: 1.1712\n",
      "Top-3 Accuracy: 1.0000\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "# **Run Evaluation** for story dataset\n",
    "dataset, lc, loaders, input_size, vocab_size, output_size, device = load_and_construct(cfg[1])\n",
    "batch = next(iter(loaders[\"train\"]))\n",
    "for model_name in [\"lstm\", \"transformer\"]:\n",
    "    print(\"*\" * 50)\n",
    "    print(f\"Evaluating model: {model_name}\")\n",
    "    print(\"*\" * 50)\n",
    "    model = initialize_model(model_name, vocab_size, input_size, output_size, device, cfg[1])\n",
    "    evaluate(model, batch, output_size, device, lc)\n",
    "    print(\"*\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Evaluating model: transformer\n",
      "**************************************************\n",
      "Loss: 0.4494\n",
      "Accuracy: 0.6667\n",
      "Perplexity: 1.5673\n",
      "Top-3 Accuracy: 1.0000\n",
      "Input: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <oov> <oov> upon <oov> <oov>\n",
      "Predicted next words: . ] ?\n",
      "\n",
      "Input: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> whisper wind <oov> leaves\n",
      "Predicted next words: ? ? ?\n",
      "\n",
      "Input: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <oov> ' s heart filled endless wonder\n",
      "Predicted next words: . ] ?\n",
      "\n",
      "Input: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> beneath stars , <oov> alone\n",
      "Predicted next words: . ] ?\n",
      "\n",
      "Input: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> voice music , soft deep\n",
      "Predicted next words: ? ! ?\n",
      "\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(loaders[\"test\"]))\n",
    "for model_name in [\"lstm\", \"transformer\"]:\n",
    "    print(\"*\" * 50)\n",
    "    print(f\"Evaluating model: {model_name}\")\n",
    "    print(\"*\" * 50)\n",
    "    model = initialize_model(model_name, vocab_size, input_size, output_size, device, cfg[1])\n",
    "    evaluate(model, batch, output_size, device, lc, test=True, n_next_words=3)\n",
    "    print(\"*\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlconda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
